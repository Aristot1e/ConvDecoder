{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plain vs. Parallel Deep Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num GPUs 3\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib notebook\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from include import *\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim\n",
    "from torch.autograd import Variable\n",
    "import pickle\n",
    "\n",
    "GPU = True\n",
    "if GPU == True:\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    #os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "    torch.cuda.set_device(0)\n",
    "    print(\"num GPUs\",torch.cuda.device_count())\n",
    "else:\n",
    "    dtype = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myimgshow(plt,img,plot_size=(4,4)):\n",
    "    plt.rcParams[\"figure.figsize\"] = plot_size\n",
    "    plt.imshow(np.moveaxis(img,0,2))\n",
    "    #plt.imshow(np.clip(img,0,1),interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path,data_size=100,post=\"jpg\"):\n",
    "    # path: directory of images\n",
    "    # img_name: a specific image\n",
    "    # black_list: images that are not desired for processing\n",
    "    images = []\n",
    "    c = 0\n",
    "    cn = 0\n",
    "    for filename in glob.glob(path+\"/*\"):\n",
    "        for fn in glob.glob(filename+\"/*\"):\n",
    "            if post not in fn:\n",
    "                continue\n",
    "\n",
    "            img = Image.open(fn)\n",
    "\n",
    "            if img.size[0] >= 512 and img.size[1] >= 512: # keep 512*512 images\n",
    "                cn += 1\n",
    "                images.append(img)\n",
    "            img.load()\n",
    "            c += 1\n",
    "    print(cn,\"3*x*y images chosen out of\",c,\"images\",\"(x,y>=512 to be cropped as 512*512)\")\n",
    "    \n",
    "    img_np_list = []\n",
    "    img_var_list = []\n",
    "    left, top, right, bottom = 0, 0, 512, 512\n",
    "    for i,img in enumerate(images):\n",
    "        img = img.crop((left, top, right, bottom)) \n",
    "        img = np.array([pil_to_np(img)])[0]\n",
    "        img_np_list.append(img / np.max(img))\n",
    "        img_var_list.append(np_to_var(img_np_list[i]).type(dtype))\n",
    "    inds = np.random.permutation(len(images))\n",
    "    np_out = [img_np_list[i] for i in inds[:data_size]]\n",
    "    var_out = [img_var_list[i] for i in inds[:data_size]]    \n",
    "    return np_out,var_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load image(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./caltech256/caltech256\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_np_list,img_var_list = load_data(path,data_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_grid([np.moveaxis(img,0,2) for img in img_np_list],nrows=5)\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_np = img_np_list\n",
    "data_var = img_var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_params = 3*512*512\n",
    "print(\"num parameters for each image = 3*512*512 =\",orig_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define network ant train it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### small compression factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mimage 0:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000431  Actual loss 0.000431 Actual loss orig 0.000431  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000711  Actual loss 0.000711 Actual loss orig 0.000711  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 1:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000028  Actual loss 0.000028 Actual loss orig 0.000028  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000052  Actual loss 0.000052 Actual loss orig 0.000052  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 2:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000039  Actual loss 0.000039 Actual loss orig 0.000039  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000059  Actual loss 0.000059 Actual loss orig 0.000059  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 3:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000913  Actual loss 0.000913 Actual loss orig 0.000913  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.001183  Actual loss 0.001183 Actual loss orig 0.001183  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 4:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000163  Actual loss 0.000163 Actual loss orig 0.000163  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000188  Actual loss 0.000188 Actual loss orig 0.000188  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 5:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000074  Actual loss 0.000074 Actual loss orig 0.000074  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000113  Actual loss 0.000113 Actual loss orig 0.000113  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 6:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000026  Actual loss 0.000026 Actual loss orig 0.000026  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000036  Actual loss 0.000036 Actual loss orig 0.000036  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 7:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000247  Actual loss 0.000247 Actual loss orig 0.000247  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000315  Actual loss 0.000315 Actual loss orig 0.000315  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 8:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000064  Actual loss 0.000064 Actual loss orig 0.000064  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000054  Actual loss 0.000054 Actual loss orig 0.000054  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 9:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 02630    Train loss 0.000104  Actual loss 0.000104 Actual loss orig 0.000103  Noise Energy 0.000000 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19990    Train loss 0.000241  Actual loss 0.000241 Actual loss orig 0.000241  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000328  Actual loss 0.000328 Actual loss orig 0.000328  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 11:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 02350    Train loss 0.000117  Actual loss 0.000117 Actual loss orig 0.000116  Noise Energy 0.000000 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19990    Train loss 0.000749  Actual loss 0.000749 Actual loss orig 0.000749  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000980  Actual loss 0.000980 Actual loss orig 0.000980  Noise Energy 0.000000   \n",
      "\n",
      "\n",
      "\u001b[1mimage 13:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 06750    Train loss 0.000198  Actual loss 0.000198 Actual loss orig 0.000198  Noise Energy 0.000000 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19990    Train loss 0.000169  Actual loss 0.000169 Actual loss orig 0.000169  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 15:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 10820    Train loss 0.000161  Actual loss 0.000161 Actual loss orig 0.000161  Noise Energy 0.000000 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19990    Train loss 0.001228  Actual loss 0.001228 Actual loss orig 0.001228  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.001880  Actual loss 0.001880 Actual loss orig 0.001880  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 17:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 09790    Train loss 0.000102  Actual loss 0.000102 Actual loss orig 0.000102  Noise Energy 0.000000 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19990    Train loss 0.000752  Actual loss 0.000752 Actual loss orig 0.000752  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 19:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 12800    Train loss 0.000052  Actual loss 0.000052 Actual loss orig 0.000052  Noise Energy 0.000000 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19990    Train loss 0.000131  Actual loss 0.000131 Actual loss orig 0.000131  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 21:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 16110    Train loss 0.000100  Actual loss 0.000100 Actual loss orig 0.000100  Noise Energy 0.000000 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19990    Train loss 0.000100  Actual loss 0.000100 Actual loss orig 0.000100  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 23:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 15690    Train loss 0.000165  Actual loss 0.000165 Actual loss orig 0.000165  Noise Energy 0.000000 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19990    Train loss 0.000228  Actual loss 0.000228 Actual loss orig 0.000228  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 25:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19160    Train loss 0.000153  Actual loss 0.000153 Actual loss orig 0.000153  Noise Energy 0.000000 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19990    Train loss 0.000021  Actual loss 0.000021 Actual loss orig 0.000021  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 27:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000128  Actual loss 0.000128 Actual loss orig 0.000128  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 02850    Train loss 0.000250  Actual loss 0.000250 Actual loss orig 0.000250  Noise Energy 0.000000 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19990    Train loss 0.000121  Actual loss 0.000121 Actual loss orig 0.000121  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 29:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000099  Actual loss 0.000099 Actual loss orig 0.000099  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000159  Actual loss 0.000159 Actual loss orig 0.000159  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 30:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000037  Actual loss 0.000037 Actual loss orig 0.000037  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000070  Actual loss 0.000070 Actual loss orig 0.000070  Noise Energy 0.000000    \n",
      "\n",
      "\n",
      "\u001b[1mimage 31:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000171  Actual loss 0.000171 Actual loss orig 0.000171  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000312  Actual loss 0.000312 Actual loss orig 0.000312  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 32:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000040  Actual loss 0.000040 Actual loss orig 0.000040  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000055  Actual loss 0.000055 Actual loss orig 0.000055  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 33:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.001819  Actual loss 0.001819 Actual loss orig 0.001819  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.002359  Actual loss 0.002359 Actual loss orig 0.002359  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 34:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000080  Actual loss 0.000080 Actual loss orig 0.000080  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000084  Actual loss 0.000084 Actual loss orig 0.000084  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 35:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000057  Actual loss 0.000057 Actual loss orig 0.000057  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000050  Actual loss 0.000050 Actual loss orig 0.000050  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 36:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000297  Actual loss 0.000297 Actual loss orig 0.000297  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000348  Actual loss 0.000348 Actual loss orig 0.000348  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 37:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000123  Actual loss 0.000123 Actual loss orig 0.000123  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000139  Actual loss 0.000139 Actual loss orig 0.000139  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 38:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.001116  Actual loss 0.001116 Actual loss orig 0.001116  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.001607  Actual loss 0.001607 Actual loss orig 0.001607  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 39:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000070  Actual loss 0.000070 Actual loss orig 0.000070  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000079  Actual loss 0.000079 Actual loss orig 0.000079  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 40:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000100  Actual loss 0.000100 Actual loss orig 0.000100  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000035  Actual loss 0.000035 Actual loss orig 0.000035  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 41:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000163  Actual loss 0.000163 Actual loss orig 0.000163  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000171  Actual loss 0.000171 Actual loss orig 0.000171  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 42:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000968  Actual loss 0.000968 Actual loss orig 0.000968  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.001007  Actual loss 0.001007 Actual loss orig 0.001007  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 43:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000074  Actual loss 0.000074 Actual loss orig 0.000074  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000233  Actual loss 0.000233 Actual loss orig 0.000233  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 44:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000481  Actual loss 0.000481 Actual loss orig 0.000481  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000502  Actual loss 0.000502 Actual loss orig 0.000502  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 45:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000032  Actual loss 0.000032 Actual loss orig 0.000032  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000033  Actual loss 0.000033 Actual loss orig 0.000033  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 46:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000064  Actual loss 0.000064 Actual loss orig 0.000064  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000072  Actual loss 0.000072 Actual loss orig 0.000072  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 47:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000021  Actual loss 0.000021 Actual loss orig 0.000021  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19990    Train loss 0.000016  Actual loss 0.000016 Actual loss orig 0.000016  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 48:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000403  Actual loss 0.000403 Actual loss orig 0.000403  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000472  Actual loss 0.000472 Actual loss orig 0.000472  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 49:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000043  Actual loss 0.000043 Actual loss orig 0.000043  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 139, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000048  Actual loss 0.000048 Actual loss orig 0.000048  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 50:\u001b[0m\n",
      "#parallel_net parameters: 99630\n",
      "#plain_net parameters: 98412\n",
      "train parallel\n",
      "shape:  [1, 90, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 00080    Train loss 0.002327  Actual loss 0.002327 Actual loss orig 0.002288  Noise Energy 0.000000 \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-001d2369b780>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m                             \u001b[0mnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                             \u001b[0mimg_clean_var\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                             \u001b[0mfind_best\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m                             )\n\u001b[1;32m     46\u001b[0m     \u001b[0mout_img_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparnet\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mparni\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/multires_deep_decoder/include/fit.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(in_size, net, img_noisy_var, num_channels, img_clean_var, num_iter, LR, OPTIMIZER, opt_input, reg_noise_std, reg_noise_decayevery, mask_var, apply_f, lr_decay_epoch, net_input, net_input_gen, find_best, weight_decay)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfind_best\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/multires_deep_decoder/include/fit.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mmse_wrt_noisy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "output_depth = [img.shape[0] for img in data_np]\n",
    "num_channels0 = 139\n",
    "num_channels = 90\n",
    "num_layers = 6\n",
    "decoders_numlayers_list = [2,4,6] # #layers for each decoding block in the parallel architecture\n",
    "decoders_last_channels = [num_channels]*3\n",
    "maxv = [np.max(img) for img in data_np]\n",
    "in_size = [32,32]\n",
    "out_size = [img[0].shape for img in data_np]\n",
    "\n",
    "rnd = 500\n",
    "numit = 20000\n",
    "rn = 0.001\n",
    "LR = 0.01\n",
    "\n",
    "par_psnr = np.zeros(len(data_np))\n",
    "plain_psnr = np.zeros(len(data_np))\n",
    "\n",
    "for i,img in enumerate(data_var):\n",
    "    \n",
    "    parnet = pardecoder(out_size[i],in_size,num_output_channels = output_depth[i],\n",
    "                     num_channels=num_channels,\n",
    "                     decoders_numlayers_list = decoders_numlayers_list,\n",
    "                     decoders_last_channels = decoders_last_channels).type(dtype)\n",
    "    \n",
    "    plainnet = skipdecoder(out_size[i],in_size,output_depth[i],num_layers,num_channels0,skips=False).type(dtype)\n",
    "    \n",
    "    bold = '\\033[1m'\n",
    "    end = '\\033[0m'\n",
    "    print(bold + \"image {}:\".format(i) + end)\n",
    "    \n",
    "    print(\"#parallel_net parameters:\",num_param(parnet))\n",
    "    print(\"#plain_net parameters:\",num_param(plainnet))\n",
    "    print(\"train parallel\") \n",
    "    mse_n, mse_t, parni, parnet = fit( in_size = in_size,\n",
    "                            num_channels=[num_channels]*(decoders_numlayers_list[-1]-1),\n",
    "                            reg_noise_std=rn,\n",
    "                            reg_noise_decayevery = rnd,\n",
    "                            num_iter=numit,\n",
    "                            LR=LR,\n",
    "                            img_noisy_var=img,\n",
    "                            net=parnet,\n",
    "                            img_clean_var=img,\n",
    "                            find_best=True,\n",
    "                            )\n",
    "    out_img_np = parnet( parni.type(dtype) ).data.cpu().numpy()[0]\n",
    "    par_psnr[i] = psnr(data_np[i],out_img_np,maxv[i])\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"train plain\")    \n",
    "    mse_n, mse_t, plainni, plainnet = fit( in_size = in_size,\n",
    "                            num_channels=[num_channels0]*(num_layers-1),\n",
    "                            reg_noise_std=rn,\n",
    "                            reg_noise_decayevery = rnd,\n",
    "                            num_iter=numit,\n",
    "                            LR=LR,\n",
    "                            img_noisy_var=img,\n",
    "                            net=plainnet,\n",
    "                            img_clean_var=img,\n",
    "                            find_best=True,\n",
    "                            #orth_reg=0.1,\n",
    "                            )    \n",
    "    out_img_np = plainnet( plainni.type(dtype) ).data.cpu().numpy()[0]\n",
    "    plain_psnr[i] = psnr(data_np[i],out_img_np,maxv[i])\n",
    "    print(\"\\n\"*2)\n",
    "    \n",
    "    with open(\"./saved_outputs/8_caltech_par_psnr\", 'wb') as fn:\n",
    "        pickle.dump(par_psnr, fn)\n",
    "    with open(\"./saved_outputs/8_caltech_plain_psnr\", 'wb') as fn:\n",
    "        pickle.dump(plain_psnr, fn)\n",
    "\n",
    "print(\"average parallel_net psnr:\",par_psnr.mean())\n",
    "print(\"average plain_net psnr:\",plain_psnr.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load saved results\n",
    "with open(\"./saved_outputs/8_caltech_par_psnr\", 'rb') as f:\n",
    "    par_psnr = pickle.load(f)\n",
    "with open(\"./saved_outputs/8_caltech_plain_psnr\", 'rb') as f:\n",
    "    plain_psnr = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(par_psnr,plain_psnr)\n",
    "plt.title(\"compression factor={}\".format(round(orig_params/num_param(parnet),1)))\n",
    "plt.xlabel(\"par_psnr\")\n",
    "plt.ylabel(\"plain_psnr\")\n",
    "plt.plot(par_psnr,par_psnr,\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### large compression factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mimage 0:\u001b[0m\n",
      "#parallel_net parameters: 24420\n",
      "#plain_net parameters: 24004\n",
      "train parallel\n",
      "shape:  [1, 44, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.002091  Actual loss 0.002091 Actual loss orig 0.002091  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 68, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.002262  Actual loss 0.002262 Actual loss orig 0.002262  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 1:\u001b[0m\n",
      "#parallel_net parameters: 24420\n",
      "#plain_net parameters: 24004\n",
      "train parallel\n",
      "shape:  [1, 44, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000211  Actual loss 0.000211 Actual loss orig 0.000211  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 68, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000267  Actual loss 0.000267 Actual loss orig 0.000267  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 2:\u001b[0m\n",
      "#parallel_net parameters: 24420\n",
      "#plain_net parameters: 24004\n",
      "train parallel\n",
      "shape:  [1, 44, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000245  Actual loss 0.000245 Actual loss orig 0.000245  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 68, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000206  Actual loss 0.000206 Actual loss orig 0.000206  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 3:\u001b[0m\n",
      "#parallel_net parameters: 24420\n",
      "#plain_net parameters: 24004\n",
      "train parallel\n",
      "shape:  [1, 44, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.003561  Actual loss 0.003561 Actual loss orig 0.003561  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 68, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.003299  Actual loss 0.003299 Actual loss orig 0.003299  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 4:\u001b[0m\n",
      "#parallel_net parameters: 24420\n",
      "#plain_net parameters: 24004\n",
      "train parallel\n",
      "shape:  [1, 44, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.001269  Actual loss 0.001269 Actual loss orig 0.001269  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 68, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.001142  Actual loss 0.001142 Actual loss orig 0.001142  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 5:\u001b[0m\n",
      "#parallel_net parameters: 24420\n",
      "#plain_net parameters: 24004\n",
      "train parallel\n",
      "shape:  [1, 44, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000302  Actual loss 0.000302 Actual loss orig 0.000302  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 68, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000310  Actual loss 0.000310 Actual loss orig 0.000310  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 6:\u001b[0m\n",
      "#parallel_net parameters: 24420\n",
      "#plain_net parameters: 24004\n",
      "train parallel\n",
      "shape:  [1, 44, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000046  Actual loss 0.000046 Actual loss orig 0.000046  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 68, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000047  Actual loss 0.000047 Actual loss orig 0.000047  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 7:\u001b[0m\n",
      "#parallel_net parameters: 24420\n",
      "#plain_net parameters: 24004\n",
      "train parallel\n",
      "shape:  [1, 44, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 12920    Train loss 0.000993  Actual loss 0.000993 Actual loss orig 0.000993  Noise Energy 0.000000 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19990    Train loss 0.000025  Actual loss 0.000025 Actual loss orig 0.000025  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 68, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000049  Actual loss 0.000049 Actual loss orig 0.000049  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 10:\u001b[0m\n",
      "#parallel_net parameters: 24420\n",
      "#plain_net parameters: 24004\n",
      "train parallel\n",
      "shape:  [1, 44, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 06270    Train loss 0.001053  Actual loss 0.001053 Actual loss orig 0.001053  Noise Energy 0.000000 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19990    Train loss 0.000142  Actual loss 0.000142 Actual loss orig 0.000142  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 12:\u001b[0m\n",
      "#parallel_net parameters: 24420\n",
      "#plain_net parameters: 24004\n",
      "train parallel\n",
      "shape:  [1, 44, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.002475  Actual loss 0.002475 Actual loss orig 0.002475  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 68, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 12940    Train loss 0.002407  Actual loss 0.002407 Actual loss orig 0.002407  Noise Energy 0.000000 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19990    Train loss 0.000590  Actual loss 0.000590 Actual loss orig 0.000590  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 68, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000674  Actual loss 0.000674 Actual loss orig 0.000674  Noise Energy 0.000000  \n",
      "\n",
      "\n",
      "\u001b[1mimage 15:\u001b[0m\n",
      "#parallel_net parameters: 24420\n",
      "#plain_net parameters: 24004\n",
      "train parallel\n",
      "shape:  [1, 44, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19780    Train loss 0.000661  Actual loss 0.000661 Actual loss orig 0.000661  Noise Energy 0.000000 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19990    Train loss 0.000184  Actual loss 0.000184 Actual loss orig 0.000184  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 68, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000510  Actual loss 0.000510 Actual loss orig 0.000510  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 18:\u001b[0m\n",
      "#parallel_net parameters: 24420\n",
      "#plain_net parameters: 24004\n",
      "train parallel\n",
      "shape:  [1, 44, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 13640    Train loss 0.002578  Actual loss 0.002578 Actual loss orig 0.002578  Noise Energy 0.000000 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19990    Train loss 0.000550  Actual loss 0.000550 Actual loss orig 0.000550  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 68, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000457  Actual loss 0.000457 Actual loss orig 0.000457  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 21:\u001b[0m\n",
      "#parallel_net parameters: 24420\n",
      "#plain_net parameters: 24004\n",
      "train parallel\n",
      "shape:  [1, 44, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 06680    Train loss 0.000482  Actual loss 0.000482 Actual loss orig 0.000482  Noise Energy 0.000000 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19990    Train loss 0.000327  Actual loss 0.000327 Actual loss orig 0.000327  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 23:\u001b[0m\n",
      "#parallel_net parameters: 24420\n",
      "#plain_net parameters: 24004\n",
      "train parallel\n",
      "shape:  [1, 44, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000771  Actual loss 0.000771 Actual loss orig 0.000771  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 68, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 11550    Train loss 0.000694  Actual loss 0.000694 Actual loss orig 0.000694  Noise Energy 0.000000 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19990    Train loss 0.001055  Actual loss 0.001055 Actual loss orig 0.001055  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 68, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000942  Actual loss 0.000942 Actual loss orig 0.000942  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 26:\u001b[0m\n",
      "#parallel_net parameters: 24420\n",
      "#plain_net parameters: 24004\n",
      "train parallel\n",
      "shape:  [1, 44, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19510    Train loss 0.000046  Actual loss 0.000046 Actual loss orig 0.000046  Noise Energy 0.000000 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19990    Train loss 0.000434  Actual loss 0.000434 Actual loss orig 0.000434  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 68, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000328  Actual loss 0.000328 Actual loss orig 0.000328  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 29:\u001b[0m\n",
      "#parallel_net parameters: 24420\n",
      "#plain_net parameters: 24004\n",
      "train parallel\n",
      "shape:  [1, 44, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 12720    Train loss 0.000500  Actual loss 0.000500 Actual loss orig 0.000500  Noise Energy 0.000000 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19990    Train loss 0.000778  Actual loss 0.000778 Actual loss orig 0.000778  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 68, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000784  Actual loss 0.000784 Actual loss orig 0.000784  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 32:\u001b[0m\n",
      "#parallel_net parameters: 24420\n",
      "#plain_net parameters: 24004\n",
      "train parallel\n",
      "shape:  [1, 44, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 06100    Train loss 0.000280  Actual loss 0.000280 Actual loss orig 0.000280  Noise Energy 0.000000 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19990    Train loss 0.006500  Actual loss 0.006500 Actual loss orig 0.006500  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 34:\u001b[0m\n",
      "#parallel_net parameters: 24420\n",
      "#plain_net parameters: 24004\n",
      "train parallel\n",
      "shape:  [1, 44, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000424  Actual loss 0.000424 Actual loss orig 0.000424  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 68, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 09170    Train loss 0.000350  Actual loss 0.000350 Actual loss orig 0.000350  Noise Energy 0.000000 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19990    Train loss 0.001059  Actual loss 0.001059 Actual loss orig 0.001059  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 68, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.001016  Actual loss 0.001016 Actual loss orig 0.001016  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 37:\u001b[0m\n",
      "#parallel_net parameters: 24420\n",
      "#plain_net parameters: 24004\n",
      "train parallel\n",
      "shape:  [1, 44, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 17940    Train loss 0.000613  Actual loss 0.000613 Actual loss orig 0.000613  Noise Energy 0.000000 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19990    Train loss 0.000279  Actual loss 0.000279 Actual loss orig 0.000279  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 68, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000224  Actual loss 0.000224 Actual loss orig 0.000224  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 40:\u001b[0m\n",
      "#parallel_net parameters: 24420\n",
      "#plain_net parameters: 24004\n",
      "train parallel\n",
      "shape:  [1, 44, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 10920    Train loss 0.000119  Actual loss 0.000119 Actual loss orig 0.000119  Noise Energy 0.000000 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19990    Train loss 0.003427  Actual loss 0.003427 Actual loss orig 0.003427  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 68, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.003365  Actual loss 0.003365 Actual loss orig 0.003365  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 43:\u001b[0m\n",
      "#parallel_net parameters: 24420\n",
      "#plain_net parameters: 24004\n",
      "train parallel\n",
      "shape:  [1, 44, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 04120    Train loss 0.000635  Actual loss 0.000635 Actual loss orig 0.000633  Noise Energy 0.000000 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19990    Train loss 0.001905  Actual loss 0.001905 Actual loss orig 0.001905  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 45:\u001b[0m\n",
      "#parallel_net parameters: 24420\n",
      "#plain_net parameters: 24004\n",
      "train parallel\n",
      "shape:  [1, 44, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000111  Actual loss 0.000111 Actual loss orig 0.000111  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 68, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 14940    Train loss 0.000089  Actual loss 0.000089 Actual loss orig 0.000089  Noise Energy 0.000000 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19990    Train loss 0.000077  Actual loss 0.000077 Actual loss orig 0.000077  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 68, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000042  Actual loss 0.000042 Actual loss orig 0.000042  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 48:\u001b[0m\n",
      "#parallel_net parameters: 24420\n",
      "#plain_net parameters: 24004\n",
      "train parallel\n",
      "shape:  [1, 44, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.002184  Actual loss 0.002184 Actual loss orig 0.002184  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 68, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.002065  Actual loss 0.002065 Actual loss orig 0.002065  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 49:\u001b[0m\n",
      "#parallel_net parameters: 24420\n",
      "#plain_net parameters: 24004\n",
      "train parallel\n",
      "shape:  [1, 44, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000068  Actual loss 0.000068 Actual loss orig 0.000068  Noise Energy 0.000000 \n",
      "\n",
      "train plain\n",
      "shape:  [1, 68, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 19990    Train loss 0.000069  Actual loss 0.000069 Actual loss orig 0.000069  Noise Energy 0.000000 \n",
      "\n",
      "\n",
      "\u001b[1mimage 50:\u001b[0m\n",
      "#parallel_net parameters: 24420\n",
      "#plain_net parameters: 24004\n",
      "train parallel\n",
      "shape:  [1, 44, 32, 32]\n",
      "optimize with adam 0.01\n",
      "Iteration 02640    Train loss 0.000936  Actual loss 0.000936 Actual loss orig 0.000934  Noise Energy 0.000000 \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-68985210c049>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m                             \u001b[0mnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                             \u001b[0mimg_clean_var\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                             \u001b[0mfind_best\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m                             )\n\u001b[1;32m     46\u001b[0m     \u001b[0mout_img_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparnet\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mparni\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/multires_deep_decoder/include/fit.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(in_size, net, img_noisy_var, num_channels, img_clean_var, num_iter, LR, OPTIMIZER, opt_input, reg_noise_std, reg_noise_decayevery, mask_var, apply_f, lr_decay_epoch, net_input, net_input_gen, find_best, weight_decay)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfind_best\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/multires_deep_decoder/include/fit.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mapply_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mimg_noisy_var\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_noisy_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2154\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2155\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2156\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2157\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "output_depth = [img.shape[0] for img in data_np]\n",
    "num_channels0 = 68\n",
    "num_channels = 44\n",
    "num_layers = 6\n",
    "decoders_numlayers_list = [2,4,6] # #layers for each decoding block in the parallel architecture\n",
    "decoders_last_channels = [num_channels]*3\n",
    "maxv = [np.max(img) for img in data_np]\n",
    "in_size = [32,32]\n",
    "out_size = [img[0].shape for img in data_np]\n",
    "\n",
    "rnd = 500\n",
    "numit = 20000\n",
    "rn = 0.001\n",
    "LR = 0.01\n",
    "\n",
    "par_psnr = np.zeros(len(data_np))\n",
    "plain_psnr = np.zeros(len(data_np))\n",
    "\n",
    "for i,img in enumerate(data_var):\n",
    "    \n",
    "    parnet = pardecoder(out_size[i],in_size,num_output_channels = output_depth[i],\n",
    "                     num_channels=num_channels,\n",
    "                     decoders_numlayers_list = decoders_numlayers_list,\n",
    "                     decoders_last_channels = decoders_last_channels).type(dtype)\n",
    "    \n",
    "    plainnet = skipdecoder(out_size[i],in_size,output_depth[i],num_layers,num_channels0,skips=False).type(dtype)\n",
    "    \n",
    "    bold = '\\033[1m'\n",
    "    end = '\\033[0m'\n",
    "    print(bold + \"image {}:\".format(i) + end)\n",
    "    \n",
    "    print(\"#parallel_net parameters:\",num_param(parnet))\n",
    "    print(\"#plain_net parameters:\",num_param(plainnet))\n",
    "    print(\"train parallel\") \n",
    "    mse_n, mse_t, parni, parnet = fit( in_size = in_size,\n",
    "                            num_channels=[num_channels]*(decoders_numlayers_list[-1]-1),\n",
    "                            reg_noise_std=rn,\n",
    "                            reg_noise_decayevery = rnd,\n",
    "                            num_iter=numit,\n",
    "                            LR=LR,\n",
    "                            img_noisy_var=img,\n",
    "                            net=parnet,\n",
    "                            img_clean_var=img,\n",
    "                            find_best=True,\n",
    "                            )\n",
    "    out_img_np = parnet( parni.type(dtype) ).data.cpu().numpy()[0]\n",
    "    par_psnr[i] = psnr(data_np[i],out_img_np,maxv[i])\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"train plain\")    \n",
    "    mse_n, mse_t, plainni, plainnet = fit( in_size = in_size,\n",
    "                            num_channels=[num_channels0]*(num_layers-1),\n",
    "                            reg_noise_std=rn,\n",
    "                            reg_noise_decayevery = rnd,\n",
    "                            num_iter=numit,\n",
    "                            LR=LR,\n",
    "                            img_noisy_var=img,\n",
    "                            net=plainnet,\n",
    "                            img_clean_var=img,\n",
    "                            find_best=True,\n",
    "                            #orth_reg=0.1,\n",
    "                            )    \n",
    "    out_img_np = plainnet( plainni.type(dtype) ).data.cpu().numpy()[0]\n",
    "    plain_psnr[i] = psnr(data_np[i],out_img_np,maxv[i])\n",
    "    print(\"\\n\"*2)\n",
    "    \n",
    "    with open(\"./saved_outputs/32_caltech_par_psnr\", 'wb') as fn:\n",
    "        pickle.dump(par_psnr, fn)\n",
    "    with open(\"./saved_outputs/32_caltech_plain_psnr\", 'wb') as fn:\n",
    "        pickle.dump(plain_psnr, fn)\n",
    "\n",
    "print(\"average parallel_net psnr:\",par_psnr.mean())\n",
    "print(\"average plain_net psnr:\",plain_psnr.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load saved results\n",
    "with open(\"./saved_outputs/32_caltech_par_psnr\", 'rb') as f:\n",
    "    par_psnr = pickle.load(f)\n",
    "with open(\"./saved_outputs/32_caltech_plain_psnr\", 'rb') as f:\n",
    "    plain_psnr = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(par_psnr,plain_psnr)\n",
    "plt.title(\"compression factor={}\".format(round(orig_params/num_param(parnet),1)))\n",
    "plt.xlabel(\"par_psnr\")\n",
    "plt.ylabel(\"plain_psnr\")\n",
    "plt.plot(par_psnr,par_psnr,\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
